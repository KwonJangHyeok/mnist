{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "def get_Bias(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape,stddev=0.1))\n",
    "def get_conv2d(X,W,B):\n",
    "    return tf.nn.conv2d(tf.matmul(X,W), strides = [1,1,1,1])+B\n",
    "def create_Layer(shape):\n",
    "    #print(shape[-2])\n",
    "    return get_weight(shape), get_Bias([shape[-1]])\n",
    "\n",
    "def Conv2d(X, W, B):\n",
    "    return tf.nn.conv2d(X,W, strides=[1,1,1,1], padding = 'SAME')+B\n",
    "def maxPoolAndRelu(T):\n",
    "    return tf.nn.max_pool(tf.nn.relu(T),strides=[1,2,2,1], ksize=[1,2,2,1], padding='SAME')\n",
    "def maxPoolAndRelu2(T):\n",
    "    return tf.nn.max_pool(tf.nn.relu(T),strides=[1,1,1,1], ksize=[1,2,2,1], padding='SAME')\n",
    "def fullLayer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weight([in_size,size])\n",
    "    B = get_Bias([size])\n",
    "    return tf.matmul(input,W)+B\n",
    "#data inputif \n",
    "#def getNextBatch(data, )\n",
    "\n",
    "def toNumpy(this,div,shape,type):\n",
    "    this=this.to_numpy()\n",
    "    this=np.divide(this,div)\n",
    "    this=this.reshape(shape)\n",
    "    this=this.astype(type)\n",
    "    return this\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('.\\\\data\\\\train.csv')\n",
    "    \n",
    "    \n",
    "    yData = data['label']\n",
    "    del data['label']\n",
    "    print(data.shape)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, yData, test_size=0.03, random_state=42)\n",
    "    x_train2, x_test2, y_train2, y_test2 = train_test_split(data, yData, test_size=0.2, random_state=42)\n",
    "\n",
    "    x_train=toNumpy(x_train,255,[-1,28,28,1],'float32')\n",
    "    x_test2=toNumpy(x_test2,255,[-1,28,28,1],'float32')\n",
    "    \n",
    "    y_train = y_train.to_numpy()\n",
    "    y_train = np.eye(10)[y_train]\n",
    "    \n",
    "    y_test2 = y_test2.to_numpy()\n",
    "    y_test2 = np.eye(10)[y_test]\n",
    "    #print(x_train)    \n",
    "    \n",
    "    X = tf.placeholder(shape=[None,28,28,1], dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[None,10], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Layer!\n",
    "    W1, B1 = create_Layer([5,5,1,32])\n",
    "    conv1 = Conv2d(X,W1,B1)\n",
    "    #conv1 = Conv2d(x_train,W1,B1)\n",
    "    conv1 = maxPoolAndRelu(conv1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_12:0\", shape=(?, 14, 14, 48), dtype=float32)\n",
      "Tensor(\"MaxPool_13:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "    #Layer2.5\n",
    "    W2, B2 = create_Layer([5,5,32,48])\n",
    "    conv2 = Conv2d(conv1,W2,B2)\n",
    "    conv2 = maxPoolAndRelu2(conv2)\n",
    "    print(conv2)\n",
    "    \n",
    "    #Layer2\n",
    "    W3, B3 = create_Layer([5,5,48,64])\n",
    "    conv2 = Conv2d(conv2,W3,B3)\n",
    "    conv2 = maxPoolAndRelu(conv2)\n",
    "    print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_4:0\", shape=(?, 3136), dtype=float32)\n",
      "Tensor(\"Relu_18:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"add_24:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "    conv2 = tf.reshape(conv2,shape=[-1,7*7*64])\n",
    "    print(conv2)\n",
    "    #1 fully connected\n",
    "    #conv2 = tf.reshape(conv2,shape=[7*7*64,1024])\n",
    "    W_fc1 = get_weight([7 * 7 * 64, 1024])\n",
    "    b_fc1 = get_Bias([1024])\n",
    "    conv2 = tf.nn.relu(tf.matmul(conv2,W_fc1)+b_fc1)\n",
    "    print(conv2)\n",
    "    \n",
    "    #2 fully connected\n",
    "    W_fc2 = get_weight([1024, 10])\n",
    "    b_fc2 = get_Bias([10])\n",
    "    outPut = tf.matmul(conv2,W_fc2)+b_fc2\n",
    "    \n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    #outPut = tf.nn.dropout(outPut, keep_prob)\n",
    "\n",
    "    print(outPut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = outPut, labels = Y))\n",
    "    \n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    y_ = tf.placeholder(shape=[None,10], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5457     8\n",
      "38509    1\n",
      "25536    9\n",
      "31803    9\n",
      "39863    8\n",
      "30639    6\n",
      "12986    2\n",
      "41067    2\n",
      "30743    7\n",
      "6839     1\n",
      "17164    6\n",
      "21723    3\n",
      "12272    1\n",
      "5030     2\n",
      "25222    7\n",
      "34680    4\n",
      "4976     3\n",
      "19565    3\n",
      "27947    6\n",
      "31133    4\n",
      "3220     9\n",
      "27143    5\n",
      "12902    2\n",
      "10151    6\n",
      "16341    0\n",
      "28553    0\n",
      "1395     0\n",
      "12793    8\n",
      "5751     6\n",
      "11911    3\n",
      "        ..\n",
      "38852    7\n",
      "27824    7\n",
      "28871    3\n",
      "4811     5\n",
      "12898    9\n",
      "30518    7\n",
      "7212     0\n",
      "33224    8\n",
      "6969     8\n",
      "37155    3\n",
      "40512    0\n",
      "31672    4\n",
      "39011    5\n",
      "28592    8\n",
      "25440    6\n",
      "11756    1\n",
      "40824    3\n",
      "1487     6\n",
      "3431     3\n",
      "41667    9\n",
      "34756    6\n",
      "29941    8\n",
      "24216    4\n",
      "22347    3\n",
      "5134     7\n",
      "6682     1\n",
      "23273    5\n",
      "33450    0\n",
      "18461    9\n",
      "1045     5\n",
      "Name: label, Length: 1260, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    start = 0\n",
    "    size = 256\n",
    "\n",
    "    #print(y_test)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(200):\n",
    "            start=0\n",
    "            for j in range(200):#while( start+size < x_train.shape[0]):\n",
    "                x_value, y_value = next_batch(size,x_train,y_train)\n",
    "                #x_value = x_train[start:start+size]\n",
    "                #y_value = y_train[start:start+size]\n",
    "\n",
    "                optimizer.run(feed_dict={X:x_value, Y:y_value, keep_prob: 0.5})\n",
    "                #start+=size\n",
    "                \n",
    "        #if i%100==0:\n",
    "            test = outPut.eval(feed_dict={X:x_test2, keep_prob: 1.0})\n",
    "            a = tf.argmax(y_test2,1).eval()\n",
    "            b = tf.argmax(test,1).eval()\n",
    "            #print('label   ', a)\n",
    "            #print('expected', b)\n",
    "            kk = tf.reduce_mean(tf.cast(tf.equal(a,b),dtype=tf.float32))\n",
    "            print(kk.eval())\n",
    "            print('')\n",
    "                \n",
    "            if(kk.eval() > 0.93):\n",
    "                test = pd.read_csv('.\\\\data\\\\test.csv')\n",
    "                test=toNumpy(test,255,[-1,28,28,1],'float32')\n",
    "                tt = tf.argmax(outPut.eval(feed_dict={X:test, keep_prob: 1.0}),1)\n",
    "                np.savetxt('my.txt',tt.eval(),fmt='%d',delimiter='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
